

# Natural Language Processing â€“ Course Introduction

**Instructor:** Prof. Pawan Goyal
**Institution:** [IIT Kharagpur](https://www.iitkgp.ac.in/)

---

## ğŸ“˜ Course Overview

* **Duration:** 12 weeks
* **Structure:** 5 modules per week
* **Support:** Two TAs â€“ Amrith Krishna and Mayank Singh
* **Contact:** Provided in the course materials

---

## ğŸ“š Recommended Books

1. **[Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)** by Jurafsky and Martin (2nd or 3rd edition)
2. **[Foundations of Statistical Natural Language Processing](https://mitpress.mit.edu/9780262133609/foundations-of-statistical-natural-language-processing/)** by Manning and SchÃ¼tze

Additional materials and [IPython Notebooks](https://jupyter.org/) will be shared for hands-on learning.

---

## ğŸ§ª Evaluation Scheme

* **Assignments:** 25% (weekly)
* **Final Exam:** 75%

---

## ğŸ“Œ Topics Covered

### Basic Topics

* **Text Processing:** Tokenization, stemming, lemmatization
* **[Language Modeling](https://en.wikipedia.org/wiki/Language_model)**
* **Morphology & Syntax**
* **[Semantics](https://en.wikipedia.org/wiki/Semantics):** Lexical and distributional semantics
* **[Word Embeddings](https://en.wikipedia.org/wiki/Word_embedding)**
* **[Topic Modeling](https://en.wikipedia.org/wiki/Topic_model)**

### Applications

* **[Entity Linking](https://en.wikipedia.org/wiki/Entity_linking)** & **[Information Extraction](https://en.wikipedia.org/wiki/Information_extraction)**
* **[Text Summarization](https://en.wikipedia.org/wiki/Automatic_summarization)**
* **[Text Classification](https://en.wikipedia.org/wiki/Text_classification)**
* **[Sentiment Analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)**

---

## ğŸ§  NLP: Scientific vs Engineering Goals

* **Scientific:** Can machines truly understand human language?
* **Engineering:** Build practical tools (e.g., [Google Translate](https://translate.google.com/), search engines, chatbots)

---

## ğŸŒ Why Study NLP?

* Text is the largest store of human knowledge ([Wikipedia](https://www.wikipedia.org/), news, scientific papers, [social media](https://en.wikipedia.org/wiki/Social_media))
* Available in many languages: multilingual processing and [machine translation](https://en.wikipedia.org/wiki/Machine_translation) are essential

---

## ğŸ§© Challenges in NLP

### Ambiguities

* **Lexical Ambiguity:** e.g., *â€œWill Will will Willâ€™s will?â€*
* **Structural Ambiguity:** e.g., *â€œThe man saw the boy with the binocularsâ€*
* **Vagueness:** e.g., *â€œItâ€™s very warmâ€*

### Social Media & Informal Text

* **Non-standard language:** *CU L8R*, hashtags, emojis
* **New words/senses:** e.g., *Googling*, *unfriending*

### Other Complexities

* **[Idioms](https://en.wikipedia.org/wiki/Idiom)**
* **[Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)**
* **Multilingual content**
* **Discourse context**

---

## ğŸ“ˆ Empirical Laws in Language

### Word Frequency

* Dominated by **function words** (e.g., *the*, *is*)
* Occasionally topic-specific **content words** (e.g., *Tom* in *Tom Sawyer*)

### Type-Token Ratio (TTR)

* **TTR = Unique Words / Total Words**
* Indicates richness and repetitiveness of vocabulary
* Varies by genre:

  * High TTR: academic texts
  * Low TTR: casual conversation

---

## ğŸ“ Tools & Approaches

* **[Probabilistic Models](https://en.wikipedia.org/wiki/Statistical_natural_language_processing)**
* **[Parsing](https://en.wikipedia.org/wiki/Parsing)**
* **[Machine Learning](https://en.wikipedia.org/wiki/Machine_learning)**
* **Language-specific rules and corpora**

---

## References

* [Jurafsky & Martin â€“ Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)
* [Manning & SchÃ¼tze â€“ Foundations of Statistical NLP](https://mitpress.mit.edu/9780262133609/foundations-of-statistical-natural-language-processing/)
* [Natural Language Processing (Wikipedia)](https://en.wikipedia.org/wiki/Natural_language_processing)
* [Word Embedding](https://en.wikipedia.org/wiki/Word_embedding)
* [Topic Modeling](https://en.wikipedia.org/wiki/Topic_model)
* [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)
* [Machine Learning](https://en.wikipedia.org/wiki/Machine_learning)



# Natural Language Processing â€“ Lecture 2

## ğŸ¯ What Do We Do in NLP?

In this lecture, Prof. Pawan Goyal explores the real-world tasks and applications tackled in **Natural Language Processing (NLP)**, emphasizing both its ambitious and practical goals.

---

## ğŸ“ Goals of NLP

### Scientific Goal

* Understand how **humans process language**
* Teach **computers** to understand and respond in **natural language**

### Engineering Goal

* Build systems that **process language** for **practical use cases**
* Examples: Translation, summarization, search engines, chatbots

---

## âš™ï¸ Ambitious Applications

### 1. **Machine Translation**

* Tools like [Google Translate](https://translate.google.com/) are widely used but **not always accurate**
* **Word Sense Disambiguation (WSD)** is crucial (e.g., "cool" â‰  "cold")

### 2. **Conversational Agents**

* Open-domain chatbots (e.g., Microsoftâ€™s [Tay](https://en.wikipedia.org/wiki/Tay_%28bot%29)) failed due to lack of control
* Domain-specific bots (e.g., course assistants) are more successful

---

## âœ… Practical Applications

### ğŸ” Information Retrieval & Query Processing

* **Spelling correction**
* **Query completion** using [language models](https://en.wikipedia.org/wiki/Language_model)

### ğŸ§  Information Extraction

* Extract structured facts (e.g., names, roles, dates) from **unstructured text**
* Applications in [Named Entity Recognition (NER)](https://en.wikipedia.org/wiki/Named-entity_recognition)

### ğŸ¤– Educational Assistants

* Use of chatbots in courses to answer routine queries with high accuracy

### ğŸ—£ï¸ Sentiment Analysis

* Analyzing opinions from [social media](https://en.wikipedia.org/wiki/Social_media), reviews, political discourse

### ğŸš« Spam Detection

* Filters in email and platforms like YouTube and Twitter
* Classify based on **textual patterns**

### ğŸŒ Machine Translation Services

* Translating full webpages and documents

### ğŸ“° Text Summarization

* Creating concise summaries from news or scientific articles

---

## ğŸ›  Challenges in NLP Applications

* Systems can make **blunders**, especially when:

  * Lacking **contextual understanding**
  * Working in **open domains**

* Yet NLP is good enough for:

  * **Search engines**
  * **Assistants**
  * **Language services**

---

## ğŸ“Œ Summary

NLP includes both high-level research and grounded engineering. Its ultimate goal is to:

* Build intelligent systems that **understand and process human language**
* Create real-world tools that solve practical problems

---

## References

* [Google Translate](https://translate.google.com/)
* [Word Sense Disambiguation](https://en.wikipedia.org/wiki/Word-sense_disambiguation)
* [Microsoft Tay Bot](https://en.wikipedia.org/wiki/Tay_%28bot%29)
* [Language Models](https://en.wikipedia.org/wiki/Language_model)
* [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)
* [Sentiment Analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)
* [Text Summarization](https://en.wikipedia.org/wiki/Automatic_summarization)




# Natural Language Processing â€“ Lecture 3

## ğŸ¤” Why is NLP Hard?

This lecture explores the inherent complexities and ambiguities in natural languages that make **NLP a challenging field**. It discusses types of ambiguities, linguistic phenomena, and why language understanding is far from trivial.

---

## ğŸ”„ Types of Ambiguity in Language

### 1. **Lexical Ambiguity**

* A word has multiple meanings.

* Example: *â€œWill Will will Willâ€™s will?â€*

  * Modal verb, proper noun, future action, noun (legal document)

* Example: *â€œRose rose to put rose roes on her rows of roses.â€*

* Famous: *â€œBuffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.â€*

  * Uses "buffalo" as city, animal, and verb (to bully)

[Lexical Ambiguity â†’ Wikipedia](https://en.wikipedia.org/wiki/Lexical_ambiguity)

---

### 2. **Structural Ambiguity**

* Different parse trees yield different meanings.

* Example: *â€œThe man saw the boy with the binoculars.â€*

  * Who has the binoculars?

* Example: *â€œFlying planes can be dangerous.â€*

  * Flying is dangerous OR flying planes are dangerous?

[Structural Ambiguity â†’ Wikipedia](https://en.wikipedia.org/wiki/Syntactic_ambiguity)

---

## ğŸ§© Other Language Complexities

### ğŸ” Vagueness and Imprecision

* Example: *â€œItâ€™s very warm here.â€*

  * What temperature is â€œwarmâ€?

* Example: *â€œIâ€™m sure she must have.â€*

  * Indicates uncertainty

---

## ğŸ˜‚ Ambiguity in Humor

* Jokes often rely on ambiguity:

  * *â€œWhy is the teacher wearing sunglasses?â€ â†’ â€œBecause the class is bright.â€*

---

## ğŸ—ï¸ Ambiguity in Headlines

* Example: *â€œHospitals are sued by 7 foot doctors.â€*
* Example: *â€œStolen painting found by tree.â€*
* Example: *â€œTeacher strikes idle kids.â€*

---

## ğŸ§  Exercise: "I Made Her Duck"

Find multiple interpretations:

1. I cooked a duck for her.
2. I cooked the duck that belongs to her.
3. I created a toy duck for her.
4. I forced her to lower her head.
5. I turned her into a duck (magic).

Ambiguity arises due to:

* **Syntactic Category Ambiguity** (noun vs. verb)
* **Possessive vs. Dative Interpretation** of â€œherâ€
* **Verb Usage**: transitive, ditransitive, action-transitive
* **Speech Ambiguity** (e.g., â€œIâ€™m aid her duckâ€ vs. â€œI made her duckâ€)

---

## ğŸ§® Parsing Explosion

* Sentence: *â€œI saw the man on the hill in Texas with the telescopeâ€¦â€*
* Number of parses increases rapidly with sentence length

  * Example: 132 parses for one sentence (relates to [Catalan numbers](https://en.wikipedia.org/wiki/Catalan_number))

---

## ğŸ—£ï¸ Why Is Language Ambiguous?

* **Efficiency:** Humans prefer concise expressions.
* **Shared Knowledge:** Listeners resolve ambiguity using context.
* NLP systems lack this shared background knowledge.

---

## ğŸ¤– Natural vs. Programming Languages

| Feature      | Natural Language            | Programming Language     |
| ------------ | --------------------------- | ------------------------ |
| Ambiguity    | High                        | None                     |
| Grammar      | Implicit, context-dependent | Explicit, formal         |
| Parsing Time | Variable, non-deterministic | Deterministic, efficient |

---

## ğŸ§µ Challenges in Modern Text (e.g., Social Media)

* Non-standard forms: *CU L8R*, @mentions, hashtags
* [Code-switching](https://en.wikipedia.org/wiki/Code-switching), new slang
* Ambiguous segmentation (e.g., â€œNew York-New Haven Railroadâ€)
* Idioms: e.g., *â€œburn the midnight oilâ€*
* Evolving usage: *â€œunfriendâ€*, *â€œretweetâ€*, *â€œGoogleâ€* as a verb

---

## ğŸ“ NLP Requires

* Knowledge of:

  * **Language structure**
  * **World knowledge**
  * **Efficient integration methods**

* **Probabilistic models** are used to:

  * Handle ambiguity
  * Predict word meaning and structure
  * Support applications like [speech recognition](https://en.wikipedia.org/wiki/Speech_recognition)

---

## References

* [Lexical Ambiguity](https://en.wikipedia.org/wiki/Lexical_ambiguity)
* [Syntactic Ambiguity](https://en.wikipedia.org/wiki/Syntactic_ambiguity)
* [Catalan Numbers](https://en.wikipedia.org/wiki/Catalan_number)
* [Speech Recognition](https://en.wikipedia.org/wiki/Speech_recognition)
* [Code-Switching](https://en.wikipedia.org/wiki/Code-switching)
* [Idioms in Language](https://en.wikipedia.org/wiki/Idiom)

